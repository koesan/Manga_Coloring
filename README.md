<div align="center">

# ğŸ¨ GAN-Based Manga Colorization Project

[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)
[![Hugging Face](https://img.shields.io/badge/Dataset-Hugging%20Face-yellow.svg)](https://huggingface.co/datasets/MichaelP84/manga-colorization-dataset)
[![Colab](https://img.shields.io/badge/Google-Colab-orange.svg)](https://colab.research.google.com/)

---

ğŸ‡¬ğŸ‡§[English](#english) | ğŸ‡¹ğŸ‡·[TÃ¼rkÃ§e](#tÃ¼rkÃ§e)

---

</div>

## English

### ğŸ‡¬ğŸ‡§

## ğŸ“– Project Overview

This project implements three state-of-the-art Generative Adversarial Network (GAN) architectures for automatic colorization of black and white manga images. Through systematic implementation and comparative analysis, we demonstrate the effectiveness of different GAN approaches in image-to-image translation, specifically addressing the unique challenges of manga colorization including line art preservation, style consistency, and culturally appropriate color application.

The project provides comprehensive implementations of Pix2Pix, Pix2PixHD, and CycleGAN models, each offering distinct advantages for the manga colorization task. By leveraging these architectures, we've created robust pipelines capable of generating high-quality, aesthetically pleasing colorizations while maintaining the artistic integrity of the original work.

### ğŸ¯ Core Objectives
- **Comparative Analysis**: Systematically evaluate performance across Pix2Pix, Pix2PixHD, and CycleGAN architectures for manga colorization
- **Technical Implementation**: Develop optimized image-to-image translation pipelines with reproducible training workflows
- **Quality Generation**: Produce visually compelling, culturally appropriate colorizations that preserve artistic intent and line work integrity
- **Research Contribution**: Advance understanding of GAN applications in digital art restoration and enhancement

## ğŸ—ï¸ Architectural Framework

### ğŸ”¬ Model Implementations

#### 1. **Pix2Pix: Supervised Learning Foundation**
Built upon the conditional GAN framework, Pix2Pix utilizes a U-Net generator architecture paired with a PatchGAN discriminator. This supervised approach leverages paired training data to establish direct mappings between grayscale and color representations. The model excels in maintaining structural consistency through its encoder-decoder structure with skip connections, making it an ideal baseline for comparative analysis. Its primary strength lies in stable convergence when paired training data is available, though it may struggle with artistic variations not represented in the training set.

#### 2. **Pix2PixHD: High-Resolution Enhancement**
Developed by NVIDIA Research, Pix2PixHD introduces a multi-scale generator architecture capable of producing high-resolution outputs (up to 2048Ã—1024). The model employs a coarse-to-fine generation strategy, first establishing basic color relationships before refining intricate details. This architecture significantly improves texture preservation and color consistency in complex scenes. The implementation includes instance-level feature normalization and multi-scale discriminators that evaluate image quality at different resolutions, resulting in photorealistic colorizations with exceptional detail preservation.

#### 3. **CycleGAN: Unsupervised Domain Adaptation**
CycleGAN revolutionizes the colorization process by eliminating the need for paired training data through its innovative cycle consistency mechanism. The dual-generator framework learns bidirectional mappings between grayscale and color domains, enforcing consistency through forward and backward translation cycles. This unsupervised approach enables training on unpaired datasets, significantly expanding the potential training data pool. The model's strength lies in its ability to learn stylistic adaptations without explicit supervision, though it requires careful balancing of adversarial and cycle consistency losses to prevent mode collapse.

## ğŸ—‚ï¸ Project Structure
```

Manga_Coloring-main/
â”œâ”€â”€ ğŸ““ CycleGan.ipynb # CycleGAN implementation notebook
â”œâ”€â”€ ğŸ““ Pix2Pix.ipynb # Pix2Pix implementation notebook  
â”œâ”€â”€ ğŸ““ pix2pixHD.ipynb # Pix2PixHD implementation notebook
â””â”€â”€ ğŸ“– README.md # Project documentation

````

### ğŸ“Š Dataset Management
The project utilizes the **MichaelP84/manga-colorization-dataset** from Hugging Face Hub, containing paired grayscale and color manga images. The dataset undergoes systematic preprocessing including:

## ğŸ“š References

### Academic Papers

- Isola, P., et al. (2017). "Image-to-Image Translation with Conditional Adversarial Networks"
- Wang, T. C., et al. (2018). "High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs"
- Zhu, J. Y., et al. (2017). "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks"

### Implementation References

- [PyTorch CycleGAN and Pix2Pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)
- [NVIDIA Pix2PixHD](https://github.com/NVIDIA/pix2pixHD)


---

## TÃ¼rkÃ§e

### ğŸ‡¹ğŸ‡· 

## ğŸ“– Proje Genel BakÄ±ÅŸ

Bu proje, siyah-beyaz manga resimlerini otomatik olarak renklendirmek iÃ§in Ã¼Ã§ farklÄ± son teknoloji Ãœretken Ã‡ekiÅŸmeli AÄŸ (GAN) mimarisini uygular. Sistematik uygulama ve karÅŸÄ±laÅŸtÄ±rmalÄ± analiz yoluyla, gÃ¶rÃ¼ntÃ¼den gÃ¶rÃ¼ntÃ¼ye Ã§eviri alanÄ±nda farklÄ± GAN yaklaÅŸÄ±mlarÄ±nÄ±n etkinliÄŸini, Ã¶zellikle Ã§izim sanatÄ± korunumu, stil tutarlÄ±lÄ±ÄŸÄ± ve kÃ¼ltÃ¼rel olarak uygun renk uygulamasÄ± gibi manga renklendirmenin benzersiz zorlarÄ±nÄ± ele alarak gÃ¶steriyoruz.

Proje, manga renklendirme gÃ¶revi iÃ§in farklÄ± avantajlar sunan Pix2Pix, Pix2PixHD ve CycleGAN modellerinin kapsamlÄ± uygulamalarÄ±nÄ± saÄŸlÄ±yor. Bu mimarilerden yararlanarak, orijinal Ã§alÄ±ÅŸmanÄ±n sanatsal bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ korurken yÃ¼ksek kaliteli, estetik olarak Ã§ekici renklendirmeler Ã¼retebilen saÄŸlam iÅŸlem hatlarÄ± oluÅŸturduk.

### ğŸ¯ Temel Hedefler

- **KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz**: Manga renklendirme iÃ§in Pix2Pix, Pix2PixHD ve CycleGAN mimarilerindeki performansÄ± sistematik olarak deÄŸerlendirmek
- **Teknik Uygulama**: Tekrarlanabilir eÄŸitim iÅŸ akÄ±ÅŸlarÄ± ile optimize edilmiÅŸ gÃ¶rÃ¼ntÃ¼den gÃ¶rÃ¼ntÃ¼ye Ã§eviri iÅŸlem hatlarÄ± geliÅŸtirmek
- **Kalite Ãœretimi**: Sanatsal niyeti ve Ã§izim iÅŸi bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ koruyan, gÃ¶rsel olarak etkileyici ve kÃ¼ltÃ¼rel olarak uygun renklendirmeler Ã¼retmek
- **AraÅŸtÄ±rma KatkÄ±sÄ±**: Dijital sanat restorasyonu ve geliÅŸtirmede GAN uygulamalarÄ±nÄ±n anlaÅŸÄ±lmasÄ±nÄ± ilerletmek

## ğŸ—ï¸ Mimari Ã‡erÃ§eve

### ğŸ”¬ Model UygulamalarÄ±

#### 1. **Pix2Pix: Denetimli Ã–ÄŸrenme Temeli**

KoÅŸullu GAN Ã§erÃ§evesi Ã¼zerine inÅŸa edilen Pix2Pix, U-Net Ã¼reteci mimarisini PatchGAN ayÄ±rÄ±cÄ±sÄ± ile birleÅŸtirir. Bu denetimli yaklaÅŸÄ±m, eÅŸleÅŸmiÅŸ eÄŸitim verilerini kullanarak gri tonlamalÄ± ve renkli temsiller arasÄ±nda doÄŸrudan eÅŸlemeler kurar. Model, atlama baÄŸlantÄ±larÄ±na sahip kodlayÄ±cÄ±-kod Ã§Ã¶zÃ¼cÃ¼ yapÄ±sÄ± aracÄ±lÄ±ÄŸÄ±yla yapÄ±sal tutarlÄ±lÄ±ÄŸÄ± korumada mÃ¼kemmeldir, bu da onu karÅŸÄ±laÅŸtÄ±rmalÄ± analiz iÃ§in ideal bir temel yapar. Ana gÃ¼cÃ¼, eÅŸleÅŸmiÅŸ eÄŸitim verisi mevcut olduÄŸunda kararlÄ± yakÄ±nsamasÄ±nda yatar, ancak eÄŸitim setinde temsil edilmeyen sanatsal varyasyonlarla zorlanabilir.

#### 2. **Pix2PixHD: YÃ¼ksek Ã‡Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ GeliÅŸtirme**

NVIDIA AraÅŸtÄ±rma tarafÄ±ndan geliÅŸtirilen Pix2PixHD, yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ Ã§Ä±ktÄ±lar (2048Ã—1024'ye kadar) Ã¼retebilen Ã§ok Ã¶lÃ§ekli bir Ã¼reteci mimarisi sunar. Model, Ã¶nce temel renk iliÅŸkilerini kurarak ardÄ±ndan karmaÅŸÄ±k detaylarÄ± hassaslaÅŸtÄ±ran kaba-ince bir Ã¼retim stratejisi kullanÄ±r. Bu mimari, karmaÅŸÄ±k sahnelerde doku korunumunu ve renk tutarlÄ±lÄ±ÄŸÄ±nÄ± Ã¶nemli Ã¶lÃ§Ã¼de iyileÅŸtirir. Uygulama, farklÄ± Ã§Ã¶zÃ¼nÃ¼rlÃ¼klerde gÃ¶rÃ¼ntÃ¼ kalitesini deÄŸerlendiren Ã§ok Ã¶lÃ§ekli ayÄ±rÄ±cÄ±lar ve Ã¶rnek seviyesi Ã¶zellik normalizasyonu iÃ§erir, bu da istisnai detay korunumu ile fotorealistik renklendirmelerle sonuÃ§lanÄ±r.

#### 3. **CycleGAN: Denetimsiz Alan Uyarlama**

CycleGAN, yenilikÃ§i dÃ¶ngÃ¼ tutarlÄ±lÄ±k mekanizmasÄ± aracÄ±lÄ±ÄŸÄ±yla eÅŸleÅŸmiÅŸ eÄŸitim verisi ihtiyacÄ±nÄ± ortadan kaldÄ±rarak renklendirme sÃ¼recini devrim niteliÄŸinde deÄŸiÅŸtirir. Ä°kili Ã¼reteci Ã§erÃ§evesi, gri tonlamalÄ± ve renkli alanlar arasÄ±nda Ã§ift yÃ¶nlÃ¼ eÅŸlemeler Ã¶ÄŸrenir, ileri ve geri Ã§eviri dÃ¶ngÃ¼leri aracÄ±lÄ±ÄŸÄ±yla tutarlÄ±lÄ±ÄŸÄ± zorlar. Bu denetimsiz yaklaÅŸÄ±m, eÅŸleÅŸmemiÅŸ veri setlerinde eÄŸitimi mÃ¼mkÃ¼n kÄ±lar ve potansiyel eÄŸitim veri havuzunu Ã¶nemli Ã¶lÃ§Ã¼de geniÅŸletir. Modelin gÃ¼cÃ¼, aÃ§Ä±k denetim olmadan stilistik uyarlamalarÄ± Ã¶ÄŸrenme yeteneÄŸinde yatar, ancak mod Ã§Ã¶kmesini Ã¶nlemek iÃ§in Ã§ekiÅŸmeli ve dÃ¶ngÃ¼ tutarlÄ±lÄ±k kayÄ±plarÄ±nÄ±n dikkatli dengelenmesini gerektirir.

## ğŸ—‚ï¸ Proje YapÄ±sÄ±

```
Manga_Coloring-main/
â”œâ”€â”€ ğŸ““ CycleGan.ipynb          # CycleGAN uygulama defteri
â”œâ”€â”€ ğŸ““ Pix2Pix.ipynb           # Pix2Pix uygulama defteri  
â”œâ”€â”€ ğŸ““ pix2pixHD.ipynb         # Pix2PixHD uygulama defteri
â””â”€â”€ ğŸ“– README.md               # Proje dokÃ¼mantasyonu
```

### ğŸ“Š Veri Seti YÃ¶netimi

Proje, Hugging Face Hub'dan **MichaelP84/manga-colorization-dataset** veri setini kullanÄ±r, eÅŸleÅŸmiÅŸ gri tonlamalÄ± ve renkli manga resimleri iÃ§erir.

## ğŸ“š Kaynaklar

### Akademik Makaleler

- Isola, P., ve diÄŸ. (2017). "Image-to-Image Translation with Conditional Adversarial Networks"
- Wang, T. C., ve diÄŸ. (2018). "High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs"
- Zhu, J. Y., ve diÄŸ. (2017). "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks"

### Uygulama KaynaklarÄ±

- [PyTorch CycleGAN ve Pix2Pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)
- [NVIDIA Pix2PixHD](https://github.com/NVIDIA/pix2pixHD)
